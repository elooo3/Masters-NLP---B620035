{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Logistic Regression ISEAR.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elooo3/Masters-NLP---B620035/blob/main/Logistic_Regression_ISEAR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ra9tWNp2yRKB"
      },
      "source": [
        "# Importing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lR3TXmInVjF",
        "outputId": "45886ac5-fba2-4525-d1a7-421359e9c9b6"
      },
      "source": [
        "# importing libraries to be used for performing set tasks\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import re # for simplifying the reviews\n",
        "import nltk # for downloading ensemble of stop words\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords') # now, download stop words\n",
        "from nltk.corpus import stopwords # import stop words into notebook\n",
        "from nltk.stem.porter import PorterStemmer # import class to be used in performing stemming \n",
        "from nltk.stem import WordNetLemmatizer # import class to be used in performing lematization"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\obemb\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\obemb\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRp7VeYsnVjK"
      },
      "source": [
        "# importing dataset\n",
        "dataset = pd.read_excel('Dataset.xlsx', sheet_name = 'isear')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtvBpuJWnVjN"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "# creating an argument that holds all stop words in english language\n",
        "stop_words = stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuRHOOxyyqVz"
      },
      "source": [
        "# Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SmadePqnVjO"
      },
      "source": [
        "corpus = [] # create a list which will contain all cleaned data\n",
        "for i in range(0, 7511): # where 7511 is the number of rows in the dataset \n",
        "#  store data in review and update after every cleaning process\n",
        "  review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i]) # re subfunction to replace any element that is not a letter with a space\n",
        "  review = review.lower() # transform all capitals to lowercase letters \n",
        "  review = review.split() # split the different elements of the sentences into different words preparing it for stemming\n",
        "  ps = PorterStemmer() # call stemming function\n",
        "  lemma = WordNetLemmatizer() #call lemmatizer function\n",
        "  all_stopwords = stopwords.words('english') # defining stop words in english\n",
        " \n",
        "  # defining a list of words to be removed from stop word list\n",
        "  unwanted_num = {'not','is','but','why','before','again','how','more','most','no','don','will','wouldn','against','aren','couldn','didn','doesn','hadn','hasn','haven','isn','wasn','weren'}\n",
        " \n",
        "  all_stopwords = [ele for ele in all_stopwords if ele not in unwanted_num] # remove all words specified above from stop word list\n",
        "\n",
        "  review = [lemma.lemmatize(word) for word in review if not word in set(all_stopwords)] # lemmatize words in the sentences for each review\n",
        "  review = ' '.join(review) # get back original format of the sentence \n",
        "  corpus.append(review) # update corpus with each clean sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ud0IYeo5zvSr"
      },
      "source": [
        "# Feature Engineering/Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_XzAn4rnVjQ"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer #import tfidf vectorizer for tokenization\n",
        "\n",
        "# create instance of the tfidf vectorizer class\n",
        "tfid = TfidfVectorizer(smooth_idf=False)\n",
        "\n",
        "X = tfid.fit_transform(corpus).toarray() # fit corpus to X\n",
        " \n",
        "y = dataset.loc[:, ['Label']].values # set target variable as the emotional states"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azQwY-GEnVjR"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0) #split dataset into training and test sets in ratio 75:25"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJudKy950U5l"
      },
      "source": [
        "# Model Fitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xbq8jRf3nVjS"
      },
      "source": [
        "# importing necessary libraries\n",
        "import pandas as pd \n",
        "from sklearn.linear_model  import Ridge,Lasso,RidgeCV, LassoCV, ElasticNet, ElasticNetCV, LogisticRegression \n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scikitplot as skl\n",
        "sns.set()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjuivN2qnVjT",
        "outputId": "3fe1461a-9c09-410a-911c-2c02115e87e4"
      },
      "source": [
        "#fit model on dataset logistic regressor\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train,y_train)\n",
        "\n",
        "y_hat = lr.predict(X_train)\n",
        "\n",
        "\n",
        "accuracy_score(y_train, y_hat) # give accuracy score on training set"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\obemb\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.8455529913012604"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtMSOxt8nVjU",
        "outputId": "55776afc-77ea-4133-aaa2-60db0256dd26"
      },
      "source": [
        "# test model on unseen data\n",
        "y_pred = lr.predict(X_test)\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.62      0.76      0.68       250\n",
            "           2       0.71      0.73      0.72       280\n",
            "           3       0.46      0.45      0.45       272\n",
            "           4       0.70      0.57      0.63       287\n",
            "           5       0.58      0.64      0.61       280\n",
            "           6       0.48      0.44      0.46       256\n",
            "           7       0.50      0.50      0.50       253\n",
            "\n",
            "    accuracy                           0.58      1878\n",
            "   macro avg       0.58      0.58      0.58      1878\n",
            "weighted avg       0.58      0.58      0.58      1878\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pgh-eth70zaP"
      },
      "source": [
        "# Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fP1B-tNnVjV",
        "outputId": "d8aab5de-c833-4b4f-b987-7fb856085566"
      },
      "source": [
        "lr = lr = LogisticRegression(multi_class = 'multinomial', solver = 'lbfgs')\n",
        "lr.fit(X_train,y_train)\n",
        "y_hat = lr.predict(X_train)\n",
        "accuracy_score(y_train, y_hat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\obemb\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.8455529913012604"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0oi0Su4nVjW",
        "outputId": "2cabe56a-b245-4be6-de3b-2d9c4158fdc0"
      },
      "source": [
        "# let's fit the data into kNN model and see how well it performs:\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "lr = LogisticRegression(multi_class = 'multinomial', solver = 'lbfgs', class_weight = 'balanced', penalty = 'l2')\n",
        "param_grid = { \n",
        "               'C' : [0.8,1,1.5]\n",
        "              }\n",
        "# param_grid = { \n",
        " #              'C' : [0.2,0.4,0.6,0.8,1,1.5]\n",
        "  #            }     \n",
        "gridsearch = GridSearchCV(lr, param_grid,verbose=3, n_jobs = 3)\n",
        "gridsearch.fit(X_train,y_train)\n",
        "# let's see the  best parameters according to gridsearch\n",
        "#gridsearch.best_params_\n",
        "gridsearch.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\obemb\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(*args, **kwargs)\n",
            "C:\\Users\\obemb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.5751803385652663"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdqzRT0PnVjX",
        "outputId": "31f5c9fc-66dd-4b41-ece1-6b2f8e236208"
      },
      "source": [
        "lr = LogisticRegression(multi_class = 'multinomial', solver = 'lbfgs', class_weight = 'balanced', penalty = 'l2', C = 1.5)\n",
        "lr.fit(X_train,y_train)\n",
        "y_hat = lr.predict(X_train)\n",
        "accuracy_score(y_train, y_hat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\obemb\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(*args, **kwargs)\n",
            "C:\\Users\\obemb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.8812355760695899"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvSdYXWrnVja",
        "outputId": "dff634ac-bebe-45bf-8b85-086238c7d446"
      },
      "source": [
        "y_pred = lr.predict(X_test)\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.64      0.74      0.69       250\n",
            "           2       0.71      0.72      0.71       280\n",
            "           3       0.46      0.44      0.45       272\n",
            "           4       0.69      0.59      0.63       287\n",
            "           5       0.59      0.65      0.62       280\n",
            "           6       0.47      0.44      0.46       256\n",
            "           7       0.49      0.49      0.49       253\n",
            "\n",
            "    accuracy                           0.58      1878\n",
            "   macro avg       0.58      0.58      0.58      1878\n",
            "weighted avg       0.58      0.58      0.58      1878\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GM7eeFbvnVjb",
        "outputId": "c17c3142-5ed8-4459-de61-1f46c615710c"
      },
      "source": [
        "y_prob_pred = lr.predict_proba(X_test)\n",
        "roc_auc_score(y_test, y_prob_pred, multi_class='ovr', average='weighted')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8624099652644618"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvhyXfJDnVjc",
        "outputId": "5a784cec-332b-46f7-ebe5-81abad17c62b"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_train,y_hat))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.85      0.92      0.89       838\n",
            "           2       0.87      0.90      0.88       803\n",
            "           3       0.78      0.82      0.80       812\n",
            "           4       0.88      0.83      0.86       793\n",
            "           5       0.85      0.85      0.85       787\n",
            "           6       0.87      0.80      0.83       793\n",
            "           7       0.82      0.78      0.80       807\n",
            "\n",
            "    accuracy                           0.85      5633\n",
            "   macro avg       0.85      0.85      0.85      5633\n",
            "weighted avg       0.85      0.85      0.85      5633\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvRaqPAInVjd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}