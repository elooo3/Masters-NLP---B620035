{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "KNN ISEAR.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elooo3/Masters-NLP---B620035/blob/main/KNN_ISEAR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgyQc-Yb4OMF"
      },
      "source": [
        "# Importing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuhdFvFPnf-n",
        "outputId": "5789b65e-a97f-4c55-87a3-944642472ded"
      },
      "source": [
        "# importing libraries to be used for performing set tasks\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import re # for simplifying the sentences\n",
        "import nltk # for downloading ensemble of stop words\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords') # now, download stop words\n",
        "from nltk.corpus import stopwords # import stop words into notebook\n",
        "from nltk.stem.porter import PorterStemmer # import class to be used in performing stemming \n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\obemb\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\obemb\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_GRD4a1nf-s"
      },
      "source": [
        "# importing dataset\n",
        "dataset = pd.read_excel('Dataset.xlsx', sheet_name = 'isear')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jl69xIvJnf-t"
      },
      "source": [
        "# Text Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGKWAml4nf-u"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "# creating an argument that holds all stop words in english language\n",
        "stop_words = stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_yfKze1nf-v"
      },
      "source": [
        "corpus = [] # create a list which will contains all cleaned data\n",
        "for i in range(0, 7511): # where 7511 is the number of sentences in the dataset \n",
        "\n",
        "#  store data in review and update after every cleaning process\n",
        "  review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i]) # re subfunction to replace any element that is not a letter with a space\n",
        "  review = review.lower() # transform all capitals to lowercase letters \n",
        "  review = review.split() # split the different elements of the sentences into different words preparing it for stemming\n",
        "  ps = PorterStemmer() # call stemming function\n",
        "  lemma = WordNetLemmatizer() #call lemmatizer function\n",
        "  all_stopwords = stopwords.words('english') # defining stop words in english\n",
        "\n",
        "  \n",
        " # defining a list of words to be removed from stop word list\n",
        "  unwanted_num = {'not','is','but','why','before','again','how','more','most','no','don','will','wouldn','against','aren','couldn','didn','doesn','hadn','hasn','haven','isn','wasn','weren'}\n",
        " \n",
        "  all_stopwords = [ele for ele in all_stopwords if ele not in unwanted_num] # remove all words specified above from stop word list\n",
        "\n",
        "  review = [lemma.lemmatize(word) for word in review if not word in set(all_stopwords)] # lemmatize words in the sentences\n",
        "  review = ' '.join(review) # get back original format of the sentence \n",
        "  corpus.append(review) # update corpus with each clean sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4N5IdoJ956Z6"
      },
      "source": [
        "# Feature Engineering/Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GnQR8_ynf-x"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer #import tfidf vectorizer for tokenization\n",
        "\n",
        "# create instance of the tfidf vectorizer class\n",
        "tfid = TfidfVectorizer(smooth_idf=False)\n",
        "\n",
        "\n",
        "X = tfid.fit_transform(corpus).toarray() # fit corpus to X\n",
        "y = dataset.loc[:, ['Label']].values # set target variable as the emotion state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur6m9Lijnf-y"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0) #split dataset into training and test sets in ratio 75:25"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJWVeZm96cWU"
      },
      "source": [
        "# Model Fitting and Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUktioPLnf-z"
      },
      "source": [
        "# importing necessary libraries\n",
        "from sklearn.neighbors import KNeighborsClassifier \n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.model_selection import KFold \n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6vQNmc4nf-0",
        "outputId": "afa15bca-2dbc-42f2-9afc-67579909eddc"
      },
      "source": [
        "# fit the data into kNN model and start tuning parameters:\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "param_grid = { 'algorithm' : ['ball_tree', 'kd_tree', 'brute'],\n",
        "               'n_neighbors' : [3,5,7,9,10,11,12,13]\n",
        "              }\n",
        "      \n",
        "gridsearch = GridSearchCV(knn, param_grid,verbose=3, n_jobs = 2)\n",
        "gridsearch.fit(X_train,y_train)\n",
        "# let's see the  best parameters according to gridsearch\n",
        "gridsearch.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\obemb\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'algorithm': 'ball_tree', 'n_neighbors': 13}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NzONaLlnf-1",
        "outputId": "ac396f56-b46d-4d98-9840-bceb678ad10a"
      },
      "source": [
        "# give accuracy score on training set\n",
        "knn = KNeighborsClassifier(algorithm = 'ball_tree', n_neighbors =13, n_jobs = 3)\n",
        "knn.fit(X_train,y_train)\n",
        "knn.score(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\obemb\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.5625776673175927"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWN-hUXjnf-2",
        "outputId": "9b71985b-d6d2-4f13-94e4-cef56af88b0d"
      },
      "source": [
        "# tune more parameters\n",
        "knn = KNeighborsClassifier(algorithm = 'ball_tree')\n",
        "param_grid = { 'weights' : ['uniform', 'distance'],\n",
        "               'n_neighbors' : [13,15,20,25,30,45]\n",
        "              }\n",
        "gridsearch = GridSearchCV(knn, param_grid,verbose=3, n_jobs = 3)\n",
        "gridsearch.fit(X_train,y_train)\n",
        "# let's see the  best parameters according to gridsearch\n",
        "gridsearch.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\obemb\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'n_neighbors': 45, 'weights': 'distance'}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deAB2Aaonf-4",
        "outputId": "4fe44c91-f658-4876-a47c-08c574efaa19"
      },
      "source": [
        "# we will use the best parameters in our k-NN algorithm and check if accuracy is increasing.\n",
        "knn = KNeighborsClassifier(algorithm = 'ball_tree', n_neighbors =45, n_jobs = 3, weights = 'distance')\n",
        "knn.fit(X_train,y_train)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\obemb\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='ball_tree', n_jobs=3, n_neighbors=45,\n",
              "                     weights='distance')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWDHg6Xtnf-5"
      },
      "source": [
        "# give accuracy score on training set\n",
        "y_pred = knn.predict(X_test)\n",
        "#print(\"The accuracy score is : \", accuracy_score(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQOrM677nf-5",
        "outputId": "742bc82f-91f5-4e44-fdcb-518b0e7e2d86"
      },
      "source": [
        "# printing more detailed results\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.50      0.76      0.60       250\n",
            "           2       0.61      0.63      0.62       280\n",
            "           3       0.41      0.27      0.32       272\n",
            "           4       0.44      0.65      0.53       287\n",
            "           5       0.64      0.41      0.50       280\n",
            "           6       0.42      0.30      0.35       256\n",
            "           7       0.41      0.40      0.41       253\n",
            "\n",
            "    accuracy                           0.49      1878\n",
            "   macro avg       0.49      0.49      0.48      1878\n",
            "weighted avg       0.49      0.49      0.48      1878\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRL09xqtnf-6",
        "outputId": "93a44ece-fac2-4a30-f0de-ab1271f77a26"
      },
      "source": [
        "# Area Under Curve\n",
        "#roc auc score\n",
        "#predicting the data\n",
        "y_prob_pred = knn.predict_proba(X_test)\n",
        "roc_auc_score(y_test, y_prob_pred, multi_class='ovr', average='weighted')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8232898994142814"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgBu7pCnnf-7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}